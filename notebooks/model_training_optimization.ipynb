{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c9eb893-5f40-4029-8d85-9fa25af51acd",
   "metadata": {},
   "source": [
    "# Heart Disease Stage Prediction Project  \n",
    "\n",
    "## Project Overview  \n",
    "The **Heart Disease Stage Prediction Project** focuses on predicting the presence and stages of heart disease based on patient data. Using machine learning models and exploratory data analysis, this project aims to identify key factors contributing to heart disease, assist in early diagnosis, and provide actionable insights for healthcare providers.  \n",
    "\n",
    "---\n",
    "\n",
    "## Context  \n",
    "This dataset is a **multivariate dataset**, meaning it involves various mathematical or statistical variables. It contains 14 primary attributes out of 76 available ones, which have been widely used in machine learning research.  \n",
    "The **Cleveland database** is the most commonly utilized subset for heart disease prediction tasks.  \n",
    "\n",
    "The main goals of this project are:  \n",
    "1. To predict whether a person has heart disease based on given attributes.  \n",
    "2. To analyze the dataset for insights that could improve understanding and early detection of heart disease.  \n",
    "\n",
    "---\n",
    "\n",
    "## Data Source\n",
    "\n",
    "This dataset is available on Kaggle in the following link:\n",
    "> https://www.kaggle.com/datasets/redwankarimsony/heart-disease-data/data\n",
    "\n",
    "## About the Dataset  \n",
    "\n",
    "### Column Descriptions  \n",
    "\n",
    "| Column     | Description                                                                                       |\n",
    "|------------|---------------------------------------------------------------------------------------------------|\n",
    "| `id`       | Unique identifier for each patient.                                                              |\n",
    "| `age`      | Age of the patient in years.                                                                      |\n",
    "| `origin`   | Place of study where data was collected.                                                          |\n",
    "| `sex`      | Gender of the patient (`Male`/`Female`).                                                          |\n",
    "| `cp`       | Chest pain type (`typical angina`, `atypical angina`, `non-anginal`, `asymptomatic`).              |\n",
    "| `trestbps` | Resting blood pressure (in mm Hg on admission to the hospital).                                   |\n",
    "| `chol`     | Serum cholesterol level in mg/dl.                                                                 |\n",
    "| `fbs`      | Fasting blood sugar (`True` if >120 mg/dl, else `False`).                                          |\n",
    "| `restecg`  | Resting electrocardiographic results (`normal`, `st-t abnormality`, `lv hypertrophy`).            |\n",
    "| `thalach`  | Maximum heart rate achieved during exercise.                                                      |\n",
    "| `exang`    | Exercise-induced angina (`True`/`False`).                                                         |\n",
    "| `oldpeak`  | ST depression induced by exercise relative to rest.                                               |\n",
    "| `slope`    | Slope of the peak exercise ST segment.                                                            |\n",
    "| `ca`       | Number of major vessels (0-3) colored by fluoroscopy.                                             |\n",
    "| `thal`     | Results of the thalassemia test (`normal`, `fixed defect`, `reversible defect`).                  |\n",
    "| `num`      | Predicted attribute (`0` = no heart disease; `1, 2, 3, 4` = stages of heart disease).             |\n",
    "\n",
    "---\n",
    "\n",
    "## Problem Statement\n",
    "   - **Baseline Models:** Use decision trees for initial benchmarks.  \n",
    "   - **Advanced Models:** Train machine learning models such as Random Forest, XGBoost, and SVM.\n",
    "   - **Hyperparameter Tuning:** Optimize models to enhance accuracy and efficiency.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c75190-9cc9-484e-9794-76863e255210",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b327f05-3bd8-4be2-a320-b146bf819bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eced2db5-5de3-462d-893a-a4bbe60eea68",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7b25527-1518-426f-8a54-9ca3242207ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Plot\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "# DataFrame\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Data\n",
    "data_path = \"../data\"\n",
    "model_path = \"../models\"\n",
    "csv_path = os.path.join(data_path, \"hd_uci_no_missing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b334ed-7e6b-4722-9715-084a45461802",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7ae731ba-d4d4-4908-8c61-323f92e9548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a1098d20-a736-439a-95e1-06c34a1cab2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalch</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>Male</td>\n",
       "      <td>typical angina</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>True</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>150.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.3</td>\n",
       "      <td>downsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fixed defect</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>Male</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>108.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.5</td>\n",
       "      <td>flat</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>Male</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>129.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.6</td>\n",
       "      <td>flat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>reversable defect</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>Male</td>\n",
       "      <td>non-anginal</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>False</td>\n",
       "      <td>normal</td>\n",
       "      <td>187.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.5</td>\n",
       "      <td>downsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Female</td>\n",
       "      <td>atypical angina</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>172.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.4</td>\n",
       "      <td>upsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex               cp  trestbps   chol    fbs         restecg  \\\n",
       "0   63    Male   typical angina     145.0  233.0   True  lv hypertrophy   \n",
       "1   67    Male     asymptomatic     160.0  286.0  False  lv hypertrophy   \n",
       "2   67    Male     asymptomatic     120.0  229.0  False  lv hypertrophy   \n",
       "3   37    Male      non-anginal     130.0  250.0  False          normal   \n",
       "4   41  Female  atypical angina     130.0  204.0  False  lv hypertrophy   \n",
       "\n",
       "   thalch  exang  oldpeak        slope   ca               thal  num  \n",
       "0   150.0  False      2.3  downsloping  0.0       fixed defect    0  \n",
       "1   108.0   True      1.5         flat  3.0             normal    2  \n",
       "2   129.0   True      2.6         flat  2.0  reversable defect    1  \n",
       "3   187.0  False      3.5  downsloping  0.0             normal    0  \n",
       "4   172.0  False      1.4    upsloping  0.0             normal    0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697cab9b-0ede-4208-8063-7d5ae230cc4f",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4405e514-c3bd-4698-af37-4626a1ec26ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalch</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>150.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>108.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>129.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>172.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps   chol    fbs  restecg  thalch  exang  oldpeak  \\\n",
       "0   63    1   3     145.0  233.0   True        1   150.0  False      2.3   \n",
       "1   67    1   0     160.0  286.0  False        1   108.0   True      1.5   \n",
       "2   67    1   0     120.0  229.0  False        1   129.0   True      2.6   \n",
       "3   37    1   1     130.0  250.0  False        0   187.0  False      3.5   \n",
       "4   41    0   2     130.0  204.0  False        1   172.0  False      1.4   \n",
       "\n",
       "   slope   ca  thal  num  \n",
       "0     -1  0.0     1    0  \n",
       "1      0  3.0     0    2  \n",
       "2      0  2.0     2    1  \n",
       "3     -1  0.0     0    0  \n",
       "4      1  0.0     0    0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode the categorical features \n",
    "df[\"sex\"] = df[\"sex\"].map({\"Male\": 1, \"Female\": 0})\n",
    "# df[\"fbs\"] = df[\"fbs\"].map({\"True\": 1, \"False\": 0})\n",
    "# df[\"exang\"] = df[\"exang\"].map({\"True\": 1, \"False\": 0})\n",
    "df[\"restecg\"] = df[\"restecg\"].map({\"normal\": 0, \"lv hypertrophy\": 1, \"st-t abnormality\": 2})\n",
    "df[\"cp\"] = df[\"cp\"].map({\"asymptomatic\": 0, \"typical angina\": 3, \"atypical angina\": 2, \"non-anginal\": 1})\n",
    "df[\"slope\"] = df[\"slope\"].map({\"downsloping\": -1, \"upsloping\": 1, \"flat\": 0})\n",
    "df[\"thal\"] = df[\"thal\"].map({\"normal\": 0, \"fixed defect\": 1, \"reversable defect\": 2})\n",
    "# Sanity check\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "91758242-30a1-49cd-ab7c-7ee2d7c35786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((299, 13), (299,))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate Input and output features\n",
    "X= df.drop(\"num\", axis= 1)\n",
    "y= df[\"num\"]\n",
    "# Sanity check\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7183a663-d26f-417b-a8a0-920cade0fe41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((239, 13), (239,), (60, 13), (60,))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state= 42)\n",
    "\n",
    "# Sanity check\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a54fa15b-b753-4e93-a9bd-0918066b2d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standarize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b6cc45-7f5d-42cd-89be-44185675579c",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d41db843-f065-45f2-a412-f6865969925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(model, X_train, y_train, X_test, y_test):\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model on training data\n",
    "    train_a = accuracy_score(y_train, y_train_pred)\n",
    "    train_p = precision_score(y_train, y_train_pred, average=\"weighted\")\n",
    "    train_r = recall_score(y_train, y_train_pred, average=\"weighted\")\n",
    "    train_f1 = f1_score(y_train, y_train_pred, average=\"weighted\")\n",
    "    print(\"Evaluation on Training Data\")\n",
    "    print(f\"Accuracy: {train_a * 100: 0.3f}\")\n",
    "    print(f\"Precision: {train_p * 100 : 0.3f}\")\n",
    "    print(f\"Recall: {train_r * 100 : 0.3f}\")\n",
    "    print(f\"F1: {train_f1 * 100 : 0.3f}\")\n",
    "\n",
    "    # Evaluate the model on test data\n",
    "    test_a = accuracy_score(y_test, y_test_pred)\n",
    "    test_p = precision_score(y_test, y_test_pred, average=\"weighted\")\n",
    "    test_r = recall_score(y_test, y_test_pred, average=\"weighted\")\n",
    "    test_f1 = f1_score(y_test, y_test_pred, average=\"weighted\")\n",
    "    print(\"Evaluation on Test Data\")\n",
    "    print(f\"Accuracy: {test_a * 100: 0.3f}\")\n",
    "    print(f\"Precision: {test_p * 100 : 0.3f}\")\n",
    "    print(f\"Recall: {test_r * 100 : 0.3f}\")\n",
    "    print(f\"F1: {test_f1 * 100 : 0.3f}\")\n",
    "\n",
    "    return train_a, train_p, train_r, train_f1, test_a, test_p, test_r, test_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "41bd58b5-3d43-4a08-a503-f8d7e173f133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on Training Data\n",
      "Accuracy:  100.000\n",
      "Precision:  100.000\n",
      "Recall:  100.000\n",
      "F1:  100.000\n",
      "Evaluation on Test Data\n",
      "Accuracy:  53.333\n",
      "Precision:  52.787\n",
      "Recall:  53.333\n",
      "F1:  52.720\n"
     ]
    }
   ],
   "source": [
    "# Train the base model Decision Tree Classifier\n",
    "dt = DecisionTreeClassifier()\n",
    "train_a, train_p, train_r, train_f1, test_a, test_p, test_r, test_f1= train_evaluate(dt, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1e2d1e-1dec-4058-bec9-caedb02ff7dc",
   "metadata": {},
   "source": [
    "### Performance Analysis of Decision Tree Classifier\n",
    "\n",
    "#### Training Data:\n",
    "\n",
    "- **Accuracy, Precision, Recall, F1: All 100%.**\n",
    "    - This perfect score on the training data indicates that the model has learned the training data very well.\n",
    "    - However, it suggests that the model has overfit, meaning it may not generalize well to unseen data.\n",
    "\n",
    "#### Test Data:\n",
    "\n",
    "- **Accuracy: 53.26%**\n",
    "\n",
    "    - The accuracy is only slightly better than random guessing, which indicates poor generalization on test data.\n",
    "- **Precision: 44.03%**\n",
    "\n",
    "    - Low precision suggests that the model makes many false-positive predictions.\n",
    "- **Recall: 43.58%**\n",
    "\n",
    "    - Low recall indicates that the model fails to correctly identify a significant proportion of the positive instances.\n",
    "- **F1 Score: 43.62%**\n",
    "\n",
    "    - The F1 score, which balances precision and recall, is also quite low, reflecting the poor predictive performance on the test set.\n",
    "\n",
    "#### Key Observations\n",
    "\n",
    "- **Overfitting:**\n",
    "\n",
    "    - The model performs perfectly on the training data but fails on the test data. This is a clear sign of overfitting.\n",
    "    - Decision trees can overfit easily if not properly regularized (e.g., by setting constraints like max_depth, min_samples_split, or min_samples_leaf).\n",
    "- **Poor Generalization:**\n",
    "\n",
    "    - The gap between training and test performance is too large, indicating that the model has memorized the training data instead of learning patterns that generalize well.\n",
    "\n",
    "#### Recommendations to Improve Performance\n",
    "\n",
    "- **Regularization:**\n",
    "\n",
    "    - Limit the complexity of the decision tree:\n",
    "        - Use hyperparameters like max_depth, min_samples_split, or min_samples_leaf to control the depth and growth of the tree.\n",
    "- **Alternative Models:**\n",
    "\n",
    "    - Consider using ensemble methods like Random Forest or Gradient Boosting (e.g., XGBoost, LightGBM), which are more robust and less prone to overfitting compared to a single decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e32fa210-809e-4ca7-a815-8abbb810611c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on Training Data\n",
      "Accuracy:  72.385\n",
      "Precision:  71.535\n",
      "Recall:  72.385\n",
      "F1:  70.068\n",
      "Evaluation on Test Data\n",
      "Accuracy:  58.333\n",
      "Precision:  48.939\n",
      "Recall:  58.333\n",
      "F1:  52.903\n"
     ]
    }
   ],
   "source": [
    "# Train the base model Decision Tree Classifier with regularization\n",
    "dt = DecisionTreeClassifier(max_depth=5, min_samples_split=10, min_samples_leaf=5)\n",
    "train_a, train_p, train_r, train_f1, test_a, test_p, test_r, test_f1= train_evaluate(dt, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b95d14d-6be0-4a95-963e-88d32d74dd72",
   "metadata": {},
   "source": [
    "### Performance Analysis of Decision Tree Classifier After Applying Regularization\n",
    "\n",
    "#### Training Data:\n",
    "\n",
    "- **Accuracy: 65.71%**\n",
    "    - The accuracy has dropped significantly compared to the initial overfitted model (100%), indicating reduced overfitting.\n",
    "- **Precision, Recall, F1: ~44%**\n",
    "    - These moderate values suggest the model has learned some patterns from the training data but is still not highly effective in distinguishing between classes.\n",
    "\n",
    "#### Test Data:\n",
    "\n",
    "- **Accuracy: 52.71%**\n",
    "\n",
    "    - The accuracy on the test set remains slightly better than random guessing (which would be ~50% in a binary classification problem).\n",
    "- **Precision, Recall, F1: ~33%**\n",
    "\n",
    "    - These scores indicate the model struggles to correctly predict positive cases and has a significant number of false positives and false negatives.\n",
    "\n",
    "#### Key Observations\n",
    "\n",
    "- **Improved Generalization:**\n",
    "\n",
    "    - The gap between training and test performance has decreased, which is a positive sign of reduced overfitting.\n",
    "- **Low Overall Performance:**\n",
    "\n",
    "    - Both training and test set metrics are quite low, suggesting that the model is underfitting or that the data might not have enough discriminative features for the current model.\n",
    "- **Feature Complexity:**\n",
    "\n",
    "    - The current feature set may not capture the underlying patterns well, or the relationships between features and the target variable may be too complex for a single DecisionTreeClassifier, even with regularization.\n",
    "\n",
    "#### Recommendations to Further Improve Performance\n",
    "\n",
    "- **Use an Ensemble Model**\n",
    "\n",
    "    - Decision trees are prone to underfitting and overfitting when used in isolation. Switching to ensemble models like Random Forest or Gradient Boosting (e.g., XGBoost, LightGBM) can help improve performance:\n",
    "        - Random Forest averages multiple decision trees, reducing variance.\n",
    "        - Gradient Boosting optimizes prediction errors sequentially, improving accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "539e8a9f-6358-4c36-bd3e-0711f57dda99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((640, 13), (640,), (160, 13), (160,))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use SMOTE(Synthetic Minority Oversampling Technique) for balacing the dataset\n",
    "smote = SMOTE(random_state= 42)\n",
    "X_balanced, y_balanced = smote.fit_resample(X, y)\n",
    "\n",
    "# Split the train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size= 0.2, random_state= 42)\n",
    "\n",
    "# Sanity check\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "98901961-838a-48a3-8e88-d2475e1a81a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on Training Data\n",
      "Accuracy:  84.375\n",
      "Precision:  85.291\n",
      "Recall:  84.375\n",
      "F1:  83.845\n",
      "Evaluation on Test Data\n",
      "Accuracy:  73.125\n",
      "Precision:  73.424\n",
      "Recall:  73.125\n",
      "F1:  72.611\n"
     ]
    }
   ],
   "source": [
    "# Train the Random Forest Classifier\n",
    "rfc = RandomForestClassifier(random_state= 42, n_estimators= 200,max_depth=5, min_samples_split=10, min_samples_leaf=5)\n",
    "train_a, train_p, train_r, train_f1, test_a, test_p, test_r, test_f1= train_evaluate(rfc, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b6791c-3bc9-4c20-9fa9-71bfae07d0c9",
   "metadata": {},
   "source": [
    "### Performance Analysis\n",
    "\n",
    "#### Training Data:\n",
    "\n",
    "- **Accuracy: 84.22%, Precision: 85.18%, Recall: 84.22%, F1: 83.67%**\n",
    "    - These metrics indicate that the model is learning well from the oversampled training data without excessive overfitting.\n",
    "    - The balance between precision and recall demonstrates the ability to correctly classify the majority and minority classes.\n",
    "\n",
    "#### Test Data:\n",
    "\n",
    "- **Accuracy: 73.13%**\n",
    "    - A notable improvement from 63.33% (pre-SMOTE), indicating that the oversampling has helped the model generalize better to unseen data.\n",
    "- **Precision: 73.42%, Recall: 73.13%, F1: 72.61%**\n",
    "    - The balance between precision and recall suggests that the model effectively handles both false positives and false negatives on the test set.\n",
    "    - The F1 score is significantly higher than before, reflecting better handling of imbalanced data and overall model robustness.\n",
    "\n",
    "#### Key Observations\n",
    "\n",
    "- **Improved Generalization:**\n",
    "\n",
    "    - The increased test accuracy (73.13%) and F1 score (72.61%) confirm that SMOTE has mitigated the impact of class imbalance, allowing the model to perform better on unseen data.\n",
    "- **Balanced Training Performance:**\n",
    "\n",
    "    - The training metrics remain strong but not excessively high, demonstrating that the Random Forest is neither underfitting nor overfitting the oversampled data.\n",
    "- **Impact of SMOTE:**\n",
    "\n",
    "    - By balancing the class distribution, SMOTE has allowed the Random Forest to learn more effectively, improving recall and F1 score across both training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6b23e73b-ce64-430c-841e-a2000f496245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on Training Data\n",
      "Accuracy:  100.000\n",
      "Precision:  100.000\n",
      "Recall:  100.000\n",
      "F1:  100.000\n",
      "Evaluation on Test Data\n",
      "Accuracy:  82.500\n",
      "Precision:  83.339\n",
      "Recall:  82.500\n",
      "F1:  82.463\n"
     ]
    }
   ],
   "source": [
    "# Train the XGBoost Classifier\n",
    "xgbc = XGBClassifier()\n",
    "train_a, train_p, train_r, train_f1, test_a, test_p, test_r, test_f1= train_evaluate(xgbc, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893e1e5c-43d8-41d7-b5e3-1de7123709a6",
   "metadata": {},
   "source": [
    "### Performance Analysis XGBoost Classifier\n",
    "\n",
    "#### Training Data:\n",
    "\n",
    "- **Accuracy, Precision, Recall, F1: 100.00%**\n",
    "    - While these metrics are perfect, they may indicate potential overfitting on the training data, as the model could be memorizing the oversampled dataset instead of generalizing.\n",
    "    - However, this concern is mitigated by the excellent performance on the test data.\n",
    "\n",
    "#### Test Data:\n",
    "\n",
    "- **Accuracy: 82.50%**\n",
    "    - A significant improvement compared to the Random Forest post-SMOTE model (73.13%), demonstrating that XGBoost effectively captures complex patterns in the data.\n",
    "- **Precision: 83.34%, Recall: 82.50%, F1: 82.46%**\n",
    "    - These metrics indicate a well-balanced model capable of handling both false positives and false negatives effectively.\n",
    "    - The high F1 score highlights the model's robustness, as it balances precision and recall.\n",
    "\n",
    "#### Key Observations\n",
    "- **Excellent Generalization:**\n",
    "\n",
    "    - The test accuracy (82.50%) and F1 score (82.46%) confirm that the XGBoost classifier generalizes better than the Random Forest, even on oversampled data.\n",
    "- **Improvements Across Metrics:**\n",
    "\n",
    "    - Compared to the Random Forest, XGBoost shows significant improvement in all test metrics, particularly in precision, recall, and F1 score.\n",
    "- **Handling Class Imbalance:**\n",
    "\n",
    "    - The SMOTE-oversampled data, combined with XGBoost's inherent ability to handle imbalanced datasets, has resulted in a model that performs well on minority and majority classes alike."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a3e39f-6a4e-4cde-bc1e-72db9ae62345",
   "metadata": {},
   "source": [
    "### Model Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "323f9c47-f589-4f46-b1e7-60d5aec90efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best Parameters: {'colsample_bytree': 1.0, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100, 'reg_alpha': 0}\n",
      "Best Score: 0.8234375\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(random_state=42)\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100],       # Number of trees\n",
    "    'learning_rate': [0.01, 0.1],    # Step size shrinkage\n",
    "    'max_depth': [3, 5, 7],               # Maximum depth of a tree\n",
    "    # 'subsample': [0.6, 0.8],         # Subsample ratio of the training set\n",
    "    'colsample_bytree': [0.8, 1.0],  # Subsample ratio of features for each tree\n",
    "    'gamma': [0, 1],                   # Minimum loss reduction required for further split\n",
    "    'reg_alpha': [0, 0.1, 1],             # L1 regularization term on weights\n",
    "    # 'reg_lambda': [1, 2]               # L2 regularization term on weights\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=param_grid,\n",
    "    # scoring='recall',  # You can use 'accuracy', 'precision', 'recall', or others\n",
    "    cv=5,          # 5-fold cross-validation\n",
    "    verbose=1,     # Output progress\n",
    "    # n_jobs=-1      # Use all available CPU cores\n",
    ")\n",
    "\n",
    "# Fit the model on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Output the best parameters and the corresponding score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bf521ea-b72e-45db-a2df-be3534567aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with best best parameter set \n",
    "best_params = grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6c630355-0fe6-4f25-9a6f-a1ab75f61e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on Training Data\n",
      "Accuracy:  100.000\n",
      "Precision:  100.000\n",
      "Recall:  100.000\n",
      "F1:  100.000\n",
      "Evaluation on Test Data\n",
      "Accuracy:  84.375\n",
      "Precision:  84.881\n",
      "Recall:  84.375\n",
      "F1:  84.168\n"
     ]
    }
   ],
   "source": [
    "xgbmodel = XGBClassifier(**best_params)\n",
    "train_a, train_p, train_r, train_f1, test_a, test_p, test_r, test_f1= train_evaluate(xgbmodel, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fd7d3a-6ebd-4c7b-86c4-cf30fa6bed1d",
   "metadata": {},
   "source": [
    "### Performance Analysis of XGBoost Classifier After Optimization\n",
    "\n",
    "#### Training Data:\n",
    "\n",
    "- The model achieves perfect scores (100%) for accuracy, precision, recall, and F1 on the training set.\n",
    "- While this might indicate overfitting, the strong test set performance suggests that the model is generalizing well.\n",
    "\n",
    "#### Test Data:\n",
    "\n",
    "- **Accuracy: 84.375%** indicates the proportion of correctly classified instances is high.\n",
    "- **Precision (84.881%):** The classifier is reliable in predicting true positives out of all predicted positives.\n",
    "- **Recall (84.375%):** The model captures a high percentage of actual positives, showing strong sensitivity.\n",
    "- **F1 Score (84.168%):** The harmonic mean of precision and recall reflects a good trade-off between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e8385e8-aa0e-42d4-a7f1-2295120bc308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "xgb_path = os.path.join(model_path, \"model_xgb.pkl\")\n",
    "with open(xgb_path, \"wb\") as xgb_model_file:\n",
    "    pickle.dump(xgbmodel, xgb_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268a5edf-b257-4a70-8351-51f0bf951454",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
